---
title: "R cookbook for analysis with REACH"
author: "R CoP"
site: bookdown::bookdown_site
documentclass: book
output:
  bookdown::gitbook: default
  #bookdown::pdf_book: default
---

# Hello World

Hi.

Bye.

<!-- If you need PDF output, uncomment bookdown::pdf_book above in YAML. You will need a LaTeX installation, e.g., https://yihui.name/tinytex/ -->

<!--chapter:end:index.Rmd-->

# Meta information
There should be here the libraries, dataset, odk and sampling frame and any other thing.


```{r}
## Importing dataset and questionnaire 
library(magrittr)
library(dplyr)
library(readxl)

main_dataset <- read.csv("inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv", na.strings = "")
loop_dataset <- read.csv("inputs/UKR2007_MSNA20_HH_dataset_loop_rcop.csv", na.strings = "")

questions <- read_xlsx("inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx",sheet="survey")
choices <- read_xlsx("inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx",sheet="choices")

```

Note that some variables were NA'ed (age, etc.) In addition, it seems the weights are already added, and both loops where combined already.

## Creating the questionnaire object

```{r, tidy=FALSE, warning=FALSE, results='hide', message=FALSE}

main_dataset <- main_dataset %>% select_if(~ !(all(is.na(.x)) | all(. == "")))

questionnaire <- load_questionnaire(data = main_dataset,
                                    questions = questions,
                                    choices = choices,
                                    choices.label.column.to.use = "label::English")

```

Probably which packages are used and version



<!--chapter:end:00_meta-information.Rmd-->

# Cleaning

## Custom packages with cleaning functions
kobold/ butteR/ auditCheckR

## Example one

## Example two


<!--chapter:end:01_cleaning.Rmd-->

# Composite indicators
composeR
dplyr::case_when

## Composite with 1 categorical variable - select one

This example will look at creating an improved source of water variable. The indicator of interest is **f11_dinking_water_source** and the options for un-improved source of water are:

- trucked_in_water_truck_with_a_tank_etc
- drinking_water_from_water_kiosk_booth_with_water_for_bottling
- bottled_water_water_purchased_in_bottles
- other_specify

```{r }
#Creating a vector of un-improved source of water
unimproved_source <- c("trucked_in_water_truck_with_a_tank_etc", "drinking_water_from_water_kiosk_booth_with_water_for_bottling", "bottled_water_water_purchased_in_bottles", "other_specify")

#Using base R
main_dataset$wash_drinkingwater_improved_source_baser <- ifelse(main_dataset$f11_dinking_water_source %in% unimproved_source, "not_improved", "improved")
table(main_dataset$f11_dinking_water_source, main_dataset$wash_drinkingwater_improved_source_baser, useNA = "ifany")

#Using base R 
main_dataset$wash_drinkingwater_improved_source_baser2 <- NA
main_dataset$wash_drinkingwater_improved_source_baser2[main_dataset$f11_dinking_water_source %in% unimproved_source] <- "not_improved"
main_dataset$wash_drinkingwater_improved_source_baser2[!(main_dataset$f11_dinking_water_source %in% unimproved_source)] <- "improved"

#Same same
table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_drinkingwater_improved_source_baser2, useNA = "ifany")

#Using case_when
main_dataset <- main_dataset %>%
  mutate(wash_improved_source_dplyr = case_when(f11_dinking_water_source %in% unimproved_source ~ "not_improved",
                                                TRUE ~ "improved"))
table(main_dataset$f11_dinking_water_source, main_dataset$wash_improved_source_dplyr, useNA = "ifany")

#Same same
table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_improved_source_dplyr)
```

In the previous example, there was no missing value. For this example, the indicator to be built will turn a yes/no question into a dummy variable (1 and 0). The variable of interest is  *b16_hohh_pension_eligible* 

```{r }
table(main_dataset$b16_hohh_pension_eligible, useNA = "ifany")

#Using base R
main_dataset$hohh_pension_eligible_dummy_baser <- ifelse(main_dataset$b16_hohh_pension_eligible == "yes", 1, 0)

table(main_dataset$b16_hohh_pension_eligible, main_dataset$hohh_pension_eligible_dummy_baser, useNA = "ifany")

#Using case_when
main_dataset <- main_dataset %>%
  mutate(hohh_pension_eligible_dummy_dplyr = case_when(b16_hohh_pension_eligible == "yes" ~ 1,
                                                b16_hohh_pension_eligible == "no" ~ 0))

table(main_dataset$b16_hohh_pension_eligible, main_dataset$hohh_pension_eligible_dummy_dplyr, useNA = "ifany")

#Same same
table(main_dataset$hohh_pension_eligible_dummy_baser, main_dataset$hohh_pension_eligible_dummy_dplyr, useNA = "ifany")
```

```{r }
#Watch out for NA. This was is not correct. 
main_dataset <- main_dataset %>%
  mutate(hohh_pension_eligible_dummy_dplyr2 = case_when(b16_hohh_pension_eligible == "yes" ~ 1,
                                                TRUE ~ 0))
table(main_dataset$b16_hohh_pension_eligible, main_dataset$hohh_pension_eligible_dummy_dplyr2, useNA = "ifany")

#Not same same
table(main_dataset$hohh_pension_eligible_dummy_baser, main_dataset$hohh_pension_eligible_dummy_dplyr2, useNA = "ifany")
```


## Composite with 2 categorical variables 
This example will look at creating an indicator whether or not the sources for drinking and for cooking, cleaning and non-drinking purposes are both improved. The indicators of interest are **f11_dinking_water_source** (and more specifically **wash_drinkingwater_improved_source_baser** from previous paragraph) and **f14_technical_water_source** (*F14_What is your HH's main source of water for cooking, cleaning, and non-drinking purposes*). 

First, a new variable has to be created, **wash_otherwater_improved_source_baser**.

```{r }
#Using base R
main_dataset$wash_otherwater_improved_source_baser <- ifelse(main_dataset$f14_technical_water_source %in% unimproved_source, "not_improved", "improved")

main_dataset$wash_bothwater_improved_source_baser <- ifelse(main_dataset$wash_drinkingwater_improved_source_baser == "improved" & main_dataset$wash_otherwater_improved_source_baser == "improved", "both_improved", "not_both_improved")

table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_otherwater_improved_source_baser, main_dataset$wash_bothwater_improved_source_baser, useNA = "ifany")
```

Now, the variable will be coded to have 3 categories instead: both improved, at least drinking water and not improved.

```{r }
main_dataset$wash_bothwater_improved_source_baser2 <- ifelse(main_dataset$wash_drinkingwater_improved_source_baser == "improved" & main_dataset$wash_otherwater_improved_source_baser == "improved", "both_improved", 
                                                             ifelse(main_dataset$wash_drinkingwater_improved_source_baser == "improved", "at_least_drinking", "not_both_improved"))

table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_otherwater_improved_source_baser, main_dataset$wash_bothwater_improved_source_baser2, useNA = "ifany")
```

```{r }
#Using dplyr
main_dataset <- main_dataset %>%
  mutate(wash_bothwater_improved_source_dplyr = case_when(wash_drinkingwater_improved_source_baser == "improved" & wash_otherwater_improved_source_baser == "improved" ~ "both_improved",
                                                          wash_drinkingwater_improved_source_baser == "improved" ~ "at_least_drinking", 
                                                          TRUE ~ "not_both_improved"
                                                          ))

table(main_dataset$wash_bothwater_improved_source_dplyr,  main_dataset$wash_bothwater_improved_source_baser2, useNA = "ifany")
```
## Composite with 1 categorical variable - select multiple
e.g. improved source of water
```{r }
# main_dataset <- main_dataset %>%
#   mutate(case_when XXXX)

```

## Composite with 1 numerical variable
This example will look at creating one a categorical variable based on a number, **f6_how_many_wood_hh_consumed_last_winter  **, 'less than 5', between 5 (included) and 10 and '10 and above'.

```{r }
main_dataset <- main_dataset %>%
  mutate(wood_consumed_categories = case_when(f6_how_many_wood_hh_consumed_last_winter < 5 ~ "less_than_5",
                                              f6_how_many_wood_hh_consumed_last_winter < 10 ~ "between5_and10",
                                              f6_how_many_wood_hh_consumed_last_winter >= 10 ~ "ten_above"))

```

## Composite with 2 numerical variables

This example will look at creating one of the indicators necessary to compute the FCS. In some cases, we need to check if the sum of number of days for 2 types of food are above 7 or not. If the sum is above 7, then it has to return 7 otherwise, the sum of both variables.

```{r }
# Combine cereals/roots and meat/eggs and make maximum 7 days
## Using base R
main_dataset$fcs_cereal_roots  <- ifelse((main_dataset$g1_cereals_consumption + main_dataset$g2_roots_consumption) > 7,
                                7,
                                main_dataset$g1_cereals_consumption + main_dataset$g2_roots_consumption)

## Using dplyr
main_dataset <- main_dataset %>%
  mutate(fcs_meat_eggs = ifelse((g5_meat_consumption + g6_eggs_consumption) > 7, 7,
                                 g5_meat_consumption + g6_eggs_consumption))


```

## Composite with 2 or more numerical variables

This example will look at creating the food consumption score. 
```{r }
main_dataset <- main_dataset %>%
  mutate(FCS_score_dplyr = fcs_cereal_roots * 2 + g3_vegetables_consumption * 1 + g4_fruits_consumption * 1 + fcs_meat_eggs * 4 + g7_pulses_consumption * 3 + g8_dairy_consumption * 4 + g9_oil_consumption * 0.5 + g10_sugar_consumption * 0.5)

main_dataset$FCS_score_baser  <- (main_dataset$fcs_cereal_roots * 2)+
  (main_dataset$g3_vegetables_consumption * 1)+
  (main_dataset$g4_fruits_consumption * 1)+
  (main_dataset$fcs_meat_eggs * 4)+
  (main_dataset$g7_pulses_consumption * 3)+
  (main_dataset$g8_dairy_consumption * 4)+
  (main_dataset$g9_oil_consumption * 0.5)+
  (main_dataset$g10_sugar_consumption * 0.5)

```



## New indicators from a loop to main dataset
e.g. aggregating the number of children going to school from a loop


<!--chapter:end:02_composite-indicators.Rmd-->

# Analysis

## hypegrammaR 
hypegrammaR follow the case mapping logic to compute analysis. It will also use the kobo questionnaire tool to help some of decision to be made.

This just load the information that will be need to conduct the analysis :

- dataset, 
- kobotool (questions and choices), 
- sample frame
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
library(hypegrammaR)
library(magrittr)
library(surveyweights)
library(srvyr)
library(readxl)

#load dataset
main_dataset <- read.csv("inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv", na.strings = "")

#load kobotool
questions <- read_xlsx("inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx",sheet="survey")
choices <- read_xlsx("inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx",sheet="choices")

#load sampling frame
my_sampling_frame <- read_excel("inputs/UKR2007_MSNA20_GCA_Weights_26AUG2020.xlsx", 
                             sheet = "for_r")
```

The questionnaire object is a list of function using the kobotool and dataset as input. For example, it will check if a given variable is a select multiple or not.
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
#create a questionnaire object
my_questionnaire <- hypegrammaR::load_questionnaire(data = main_dataset,
                                    questions = questions,
                                    choices = choices,
                                    choices.label.column.to.use = "label::English")

```

The weighting function is created by the weighting_fun_from_samplinframe from the surveyweights package. It calculates the design weight based on the sampling frame and the dataset. The stratification names values used in the sampling frame and the dataset **HAS** to be the same. 
What it does, it create a function that will calculate the weights based on your dataset. 
*(It was defined as a function so it could re-calculate weights depending on the subset. however, the current guidelines is to keep the same design weights through all the assessement; the function still works for that case)*
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
#create a weigthing function
my_weigthing_function <- surveyweights::weighting_fun_from_samplingframe(sampling.frame = my_sampling_frame,
                                                                      data.stratum.column = "strata",
                                                                      sampling.frame.population.column = "population", 
                                                                      sampling.frame.stratum.column = "strata", 
                                                                      data = main_dataset)
```
If you want to add the weights to your dataframe this is how you can do it.
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
#optional, if you want to add the weights into the dataset.
main_dataset$stratum.weight <- my_weigthing_function(main_dataset)

```


hypegrammaR uses cases to choose what type analysis to do. A "case" for hypegrammaR is a character string CASE_XXXX_YYYY_ZZZZ where :

- XXXX: hypothesis type (group_difference, direct_reporting)  
- YYYY: dependent var type (categorical, numerical)  
- ZZZZ: independent var type (categorical, numerical, *empty* if no independent variable) . 

All cases implemented can been seen with this code.

```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
hypegrammaR:::list_all_cases(implemented_only = T)
```


If you want to know what are the different proportion of the displacement status for each strata. The following information I need are:
hypothesis : group_difference  
dependent variable : d1_hh_displacement_status -> categorical  
independent_variable : strata -> categorical 
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
#analysis 
my_case <- hypegrammaR::map_to_case(hypothesis.type = "group_difference",
                       dependent.var.type = "categorical",
                       independent.var.type = "categorical")

my_case
```

The function map_to_result will calculate your summary statistics, it will take a couple of arguments.
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
my_results <- hypegrammaR::map_to_result(data = main_dataset, 
                            dependent.var = "d1_hh_displacement_status", 
                            independent.var = "strata",
                            case = my_case, 
                            weighting = my_weigthing_function,
                            questionnaire = my_questionnaire,
                            confidence_level = .90)
```

The result object is a list with several information:

- parameters: returns the information used of that analysis
- summary statistics: returns the summary statistics in a tidy format
- hypothesis test: returns hypothesis testing information (if avalaible)
- message: returns a message (if the analysis went well or not)

```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
my_results$summary.statistic
```


If you need to run several analysis, you can use a data analysis plan (DAP) file which is a file that comprises of the following columns:
  
- dependent.variable: name of the dependent variable (kobo name, column name)  
- dependent.variable.type: type of the dependent variable (categorical or numerical or empty)  
- independent.variable: name of the independent variable (kobo name, column name)  
- independent.variable.type: type of the independent variable (categorical or numerical or empty)  
- repeat.for.variable: name of the variable to repeat the analysis for (e.g per camp or district or governorate)  
- hypothesis.type: type of hypothesis (group_difference, direct_reporting)
- you can have other columns to help you write the analysis plan such as RQ and sub RQ

**You cannot have duplicate columns**

Below, I am creating the DAP, but you could read a csv file. It has :

- 2 categorical variables, (select multiple type in kobo), *l4_which_difficult_access_health* and *j10_education_security_concerns_in_the_vicinity_of_facility*
- 2 categorical variables, (select one type in kobo), *b9_hohh_marital_status* and *d1_hh_displacement_status*,
- 2 numerical variables (integer type in kobo): *b7_hohh_age* and *b5_age*

It will repeat the analysis 3 times for each dependent variable:

- using the *strata* variable as independent variable (first 6 rows), 
- using no independent variable, for the complete dataset (national level?), (second 6 rows),
- using the *b9_hohh_marital_status* as independent variable but repeating each strata (last 6 rows)
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}

#dap 
my_dap <- data.frame(dependent.variable = rep(c("l4_which_difficult_access_health", "j10_education_security_concerns_in_the_vicinity_of_facility", "b7_hohh_age",
                 "b5_age", "b9_hohh_marital_status",
                    "d1_hh_displacement_status"), 3),
                     dependent.variable.type = rep(c("categorical", "categorical", "numerical", "numerical", "categorical", "categorical"),3),
                     independent.variable = c(rep("strata", 6), rep(NA, 6), rep("b9_hohh_marital_status", 6)),
                     independent.variable.type = c(rep("categorical", 6), rep(NA, 6), rep("categorical", 6)), 
                     hypothesis.type = c(rep("group_difference", 6), rep("direct_reporting", 6), rep("group_difference", 6)), 
                     repeat.for.variable = c(rep(NA, 12), rep("strata", 6))
                     )

my_dap
```

To use a DAP, you need to use the function **from_analysisplan_map_to_output** instead of the combination of **map_to_case** and **map_to_result**. It will look for the case itself. **from_analysisplan_map_to_output** a list of list of results. So you need to wriggle a bit around to come to a master dataframe.
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
my_results <- hypegrammaR::from_analysisplan_map_to_output(data =main_dataset,
                                analysisplan = my_dap,
                                weighting = my_weigthing_function,
                                questionnaire = my_questionnaire,
                                confidence_level = .90)

long_table <- my_results$results %>% 
  lapply(function(x) x[["summary.statistic"]]) %>% 
  do.call(rbind, .)

long_table %>% head(20)
```

## srvyr package

"The srvyr package aims to add dplyr like syntax to the survey package." It is a very useful package for a variety of aggregations of survey data.

```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
###makes some additions. 
library(tidyverse)
library(butteR)
library(srvyr)
library(kableExtra)
df<-read_csv("inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv")
dfsvy<-as_survey(df)
```

### Categorical variables
srvyr package allows categorical variables to be broken down using a similar syntax as dplyr.  Using dplyr you might typically calculate a percent mean as follows:
```{r}

df %>% 
  group_by(b9_hohh_marital_status) %>% 
  summarise(
    n=n()
  ) %>% 
  ungroup() %>% 
  mutate(
    pct_mean=n/sum(n)
  )

```

To calculate the percent mean of a categorical variable using srvyr object is required. The syntax is quite similar to dplyr, but a bit less verbose. By specifying the vartype as "ci" we also get the upper and lower confidence intervals

```{r}
dfsvy %>% 
  group_by(b9_hohh_marital_status) %>% 
  summarise(
    pct_mean = survey_mean(vartype = "ci")
  )

```


### Numeric variables
srvyr treats the calculation/aggregation of numeric variables differently in an attempt to mirror dplyr syntax 

to calculate the mean and median expenditure in dplyr you would likely do the following
```{r}

df %>% 
  summarise(
    mean_expenditure= mean(n1_HH_total_expenditure,na.rm=T),
    median_expenditure=median(n1_HH_total_expenditure,na.rm=T),
    )

```

If you wanted to subset this by another variable in dplyr you would add the group_by argument
```{r}

df %>% 
  group_by(strata) %>% 
  summarise(
    mean_expenditure= mean(n1_HH_total_expenditure,na.rm=T),
    median_expenditure=median(n1_HH_total_expenditure,na.rm=T),
    )

```

This is the reason why the syntax also varies between categorical and numeric variables in srvyr. Therefore, to do the same using srvyr you would do the following (with a survey object). Note that due to this difference in syntax the na.rm argument works for numeric variables, but **does not work** for categorical variables. This was modified when srvyr was updated from v 0.3.8

```{r}
dfsvy %>% 
  summarise(
   mean= survey_mean(n1_HH_total_expenditure,na.rm=T,vartype = "ci"),
  )


```

similar to dplyr you can easily add a group_by argument to add a subset calculation
```{r}
dfsvy %>% 
  group_by(strata) %>% 
  summarise(
   mean= survey_mean(n1_HH_total_expenditure,na.rm=T,vartype = "ci"),
  )


```

## butteR survey_collapse




The survey_collapse function available in butteR aggregates both categorical and numerical columns of a srvyr object. It provides a standardized format output that includes mean/pct mean (point estimates), and the upper/lower confidence intervals along with the unweighted number/frequency for each response option. The survey_collapse function is built around the great srvyr package. The srvyr package is a more modern/tidyverse style wrapper for the survey package. Both the srvyr and survye packages are great and there use is highligh encouraged. 

The main advantages of survey_collapse

1. The standardized output produced
2. Ability to analyze both categorical and numerical columns with a consistent syntax
3. Batch analyses and ability to perform many different subsetting investigations with ease

Below is an example of its use.

First we must read in some data and make it into a srvyr object

```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
###makes some additions. 
library(tidyverse)
library(butteR)
library(srvyr)
library(kableExtra)
df<-read_csv("inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv")
dfsvy<-as_survey(df)
```

For the purpose of the example I next choose a variety of different column types to analyze. As you can see I have selected select_one (categorical), select_multiple (binary categorical), and numerical columns. I then put these all into one vector.
```{r,message=F,warning=F, results="hide"}
# here are some random concatenated select multiple parent questions
select_multiple_parent_cols<-c("l4_which_difficult_access_health",
                        "j10_education_security_concerns_in_the_vicinity_of_facility")
numeric_cols<- c("b7_hohh_age",
                 "b5_age")
select_one_cols<- c("b9_hohh_marital_status",
                    "d1_hh_displacement_status")
mixed_columns<- c(select_multiple_parent_cols, numeric_cols, select_one_cols)
```


A nice feature of the standardized output produced by survey_collapse is that you can perform variety of different types of analyses and then bind them together into one dataframe/tibble.

Therefore I fill an empty list with analysis to facilitate binding later. For the first analyses I simply aggregate all the columns specified as mean/pct mean. I next analyze the same variable but this time subset/disaggreated by the strata column. It's a good idea to mutate an extra column indicating what exact analysis was done so that when they are binded together later they can more easily be manipulated

```{r,message=F,warning=F, results="hide"}
outputs<-list()

outputs$overall<-butteR::survey_collapse(df = dfsvy,vars_to_analyze = mixed_columns) %>% 
  mutate(analysis_level= "overall")

outputs$strata<-butteR::survey_collapse(df = dfsvy,vars_to_analyze = mixed_columns,disag = "strata") %>% 
  mutate(analysis_level= "strata")
```


Here is an example of what the long format data looks like as a table.
```{r, echo =F}
outputs$strata %>% 
  head(100) %>% 
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```


This is a great format for manipulating/filtering and then graphing with ggplot
```{r}
output_df<- bind_rows(outputs)

output_df %>% 
  filter(analysis_level=="overall") %>% 
  mutate(question_val= paste0(variable,".",variable_val)) %>% 
  ggplot(aes(x= question_val,y= `mean/pct`))+
  geom_point(stat="identity", position = position_dodge(width = 0.3))+
  geom_errorbar(aes(ymin= `mean/pct_low`, ymax= `mean/pct_upp`), 
                width=0.2,position = position_dodge(width = 0.3))+
  scale_y_continuous(labels = scales::percent,breaks = seq(0,1,by=0.1))+
  coord_flip()+
  theme_bw()+
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle=90),
    legend.title= element_blank()
  ) 


# Easy to plot subset findings as well!
output_df %>% 
  filter(analysis_level=="strata") %>% 
  mutate(question_val= paste0(variable,".",variable_val)) %>% 
  ggplot(aes(x= question_val,y= `mean/pct`, color=subset_1_val))+
  geom_point(stat="identity", position = position_dodge(width = 0.3))+
  geom_errorbar(aes(ymin= `mean/pct_low`, ymax= `mean/pct_upp`), 
                width=0.2,position = position_dodge(width = 0.3))+
  scale_y_continuous(labels = scales::percent,breaks = seq(0,1,by=0.1))+
  coord_flip()+
  theme_bw()+
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle=90),
    legend.title= element_blank()
  ) 


```

### select_one 
### select_mutiple

## Analysis with numerical variables
Summarytools (CRAN package)
Spatstat
hypegrammaR / koboquest / butteR
### Averages
### Median

## Weights
surveyweights
survey (CRAN package)
srvyr (CRAN package)

## Repeating the above

## Top 3

## Borda count

## Hypothesis testing
### T-test
### ANOVA
### chi-squares



<!--chapter:end:03_analysis.Rmd-->

# Outputs

## From long to large table
How to move from a tidy format to a large format

## Merge file
How to create a merge file

## Graphs
### spider graphs
### prison graphs
### venn diagram

## Labels
### change from xml to label
### change from label to xml

## Dashboarding - Sharing information
Html files
Tableau
Power BI
Shiny

## Outputs with hypothesis testing results

<!--chapter:end:04_outputs.Rmd-->

# Miscellaneous

Geocoding - stringdist
R output to be used with SPSS

Individual loops analysis
Calculation of CI

guidelines on hypothesis testing

<!--chapter:end:05_miscellaneous.Rmd-->

