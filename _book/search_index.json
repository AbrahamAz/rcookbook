[["analysis.html", "5 Analysis 5.1 hypegrammaR 5.2 srvyr package 5.3 butteR survey_collapse 5.4 Analysis with numerical variables 5.5 Weights 5.6 Repeating the above 5.7 Top 3 5.8 Borda count 5.9 Hypothesis testing", " 5 Analysis 5.1 hypegrammaR hypegrammaR follow the case mapping logic to compute analysis. It will also use the kobo questionnaire tool to help some of decision to be made. This just load the information that will be need to conduct the analysis : dataset, kobotool (questions and choices), sample frame library(hypegrammaR) library(magrittr) library(surveyweights) library(srvyr) library(readxl) library(spatstat) #load dataset main_dataset &lt;- read.csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;, na.strings = &quot;&quot;) #load kobotool questions &lt;- read_xlsx(&quot;inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx&quot;,sheet=&quot;survey&quot;) choices &lt;- read_xlsx(&quot;inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx&quot;,sheet=&quot;choices&quot;) #load sampling frame my_sampling_frame &lt;- read_excel(&quot;inputs/UKR2007_MSNA20_GCA_Weights_26AUG2020.xlsx&quot;, sheet = &quot;for_r&quot;) The questionnaire object is a list of function using the kobotool and dataset as input. For example, it will check if a given variable is a select multiple or not. #create a questionnaire object my_questionnaire &lt;- hypegrammaR::load_questionnaire(data = main_dataset, questions = questions, choices = choices, choices.label.column.to.use = &quot;label::English&quot;) The weighting function is created by the weighting_fun_from_samplinframe from the surveyweights package. It calculates the design weight based on the sampling frame and the dataset. The stratification names values used in the sampling frame and the dataset HAS to be the same. What it does, it create a function that will calculate the weights based on your dataset. (It was defined as a function so it could re-calculate weights depending on the subset. however, the current guidelines is to keep the same design weights through all the assessement; the function still works for that case) #create a weigthing function my_weigthing_function &lt;- surveyweights::weighting_fun_from_samplingframe(sampling.frame = my_sampling_frame, data.stratum.column = &quot;strata&quot;, sampling.frame.population.column = &quot;population&quot;, sampling.frame.stratum.column = &quot;strata&quot;, data = main_dataset) If you want to add the weights to your dataframe this is how you can do it. #optional, if you want to add the weights into the dataset. main_dataset$stratum.weight &lt;- my_weigthing_function(main_dataset) hypegrammaR uses cases to choose what type analysis to do. A case for hypegrammaR is a character string CASE_XXXX_YYYY_ZZZZ where : XXXX: hypothesis type (group_difference, direct_reporting) YYYY: dependent var type (categorical, numerical) ZZZZ: independent var type (categorical, numerical, empty if no independent variable) . All cases implemented can been seen with this code. hypegrammaR:::list_all_cases(implemented_only = T) ## [1] &quot;CASE_group_difference_categorical_categorical&quot; ## [2] &quot;CASE_group_difference_numerical_categorical&quot; ## [3] &quot;CASE_direct_reporting_numerical_&quot; ## [4] &quot;CASE_direct_reporting_categorical_&quot; ## [5] &quot;CASE_direct_reporting_categorical_categorical&quot; ## [6] &quot;CASE_direct_reporting_numerical_categorical&quot; ## [7] &quot;CASE_limit_categorical&quot; ## [8] &quot;CASE_limit_numerical&quot; ## [9] &quot;CASE_correlation_numerical_numerical&quot; ## [10] &quot;CASE_correlation_categorical_numerical&quot; If you want to know what are the different proportion of the displacement status for each strata. The following information I need are: hypothesis : group_difference dependent variable : d1_hh_displacement_status -&gt; categorical independent_variable : strata -&gt; categorical #analysis my_case &lt;- hypegrammaR::map_to_case(hypothesis.type = &quot;group_difference&quot;, dependent.var.type = &quot;categorical&quot;, independent.var.type = &quot;categorical&quot;) my_case ## [1] &quot;CASE_group_difference_categorical_categorical&quot; ## attr(,&quot;class&quot;) ## [1] &quot;analysis_case&quot; The function map_to_result will calculate your summary statistics, it will take a couple of arguments. my_results &lt;- hypegrammaR::map_to_result(data = main_dataset, dependent.var = &quot;d1_hh_displacement_status&quot;, independent.var = &quot;strata&quot;, case = my_case, weighting = my_weigthing_function, questionnaire = my_questionnaire, confidence_level = .90) The result object is a list with several information: parameters: returns the information used of that analysis summary statistics: returns the summary statistics in a tidy format hypothesis test: returns hypothesis testing information (if avalaible) message: returns a message (if the analysis went well or not) my_results$summary.statistic %&gt;% head() ## dependent.var independent.var ## 1 d1_hh_displacement_status strata ## 2 d1_hh_displacement_status strata ## 3 d1_hh_displacement_status strata ## 4 d1_hh_displacement_status strata ## 5 d1_hh_displacement_status strata ## 6 d1_hh_displacement_status strata ## dependent.var.value ## 1 displaced_and_idp_status ## 2 displaced_but_does_not_have_idp_status ## 3 no ## 4 partially_displaced_and_dont_have_idp_status ## 5 partially_displaced_and_have_idp_status ## 6 used_to_be_displaced_but_returned_and_has_no_status_of_idp ## independent.var.value numbers se min max ## 1 20km_rural 0.046683047 NA 0.0261473551 0.067218738 ## 2 20km_rural 0.002457002 NA -0.0023622501 0.007276255 ## 3 20km_rural 0.911547912 NA 0.8839068400 0.939188983 ## 4 20km_rural 0.007371007 NA -0.0009555979 0.015697613 ## 5 20km_rural 0.022113022 NA 0.0077984141 0.036427630 ## 6 20km_rural 0.009828010 NA 0.0002251810 0.019430839 If you need to run several analysis, you can use a data analysis plan (DAP) file which is a file that comprises of the following columns: dependent.variable: name of the dependent variable (kobo name, column name) dependent.variable.type: type of the dependent variable (categorical or numerical or empty) independent.variable: name of the independent variable (kobo name, column name) independent.variable.type: type of the independent variable (categorical or numerical or empty) repeat.for.variable: name of the variable to repeat the analysis for (e.g per camp or district or governorate) hypothesis.type: type of hypothesis (group_difference, direct_reporting) you can have other columns to help you write the analysis plan such as RQ and sub RQ You cannot have duplicate columns Below, I am creating the DAP, but you could read a csv file. It has : 2 categorical variables, (select multiple type in kobo), l4_which_difficult_access_health and j10_education_security_concerns_in_the_vicinity_of_facility 2 categorical variables, (select one type in kobo), b9_hohh_marital_status and d1_hh_displacement_status, 2 numerical variables (integer type in kobo): b7_hohh_age and b5_age It will repeat the analysis 3 times for each dependent variable: using the strata variable as independent variable (first 6 rows), using no independent variable, for the complete dataset (national level?), (second 6 rows), using the b9_hohh_marital_status as independent variable but repeating each strata (last 6 rows) #dap my_dap &lt;- data.frame(dependent.variable = c(rep(c(&quot;l4_which_difficult_access_health&quot;, &quot;j10_education_security_concerns_in_the_vicinity_of_facility&quot;, &quot;b7_hohh_age&quot;, &quot;b5_age&quot;, &quot;b9_hohh_marital_status&quot;, &quot;d1_hh_displacement_status&quot;), 2), c(&quot;l4_which_difficult_access_health&quot;, &quot;j10_education_security_concerns_in_the_vicinity_of_facility&quot;, &quot;b7_hohh_age&quot;, &quot;b5_age&quot;, &quot;d1_hh_displacement_status&quot;)), dependent.variable.type = c(rep(c(&quot;categorical&quot;, &quot;categorical&quot;, &quot;numerical&quot;, &quot;numerical&quot;, &quot;categorical&quot;, &quot;categorical&quot;),2),&quot;categorical&quot;, &quot;categorical&quot;, &quot;numerical&quot;, &quot;numerical&quot;, &quot;categorical&quot;), independent.variable = c(rep(&quot;strata&quot;, 6), rep(NA, 6), rep(&quot;b9_hohh_marital_status&quot;, 5)), independent.variable.type = c(rep(&quot;categorical&quot;, 6), rep(NA, 6), rep(&quot;categorical&quot;, 5)), hypothesis.type = c(rep(&quot;group_difference&quot;, 6), rep(&quot;direct_reporting&quot;, 6), rep(&quot;group_difference&quot;, 5)), repeat.for.variable = c(rep(NA, 12), rep(&quot;strata&quot;, 5)) ) my_dap ## dependent.variable ## 1 l4_which_difficult_access_health ## 2 j10_education_security_concerns_in_the_vicinity_of_facility ## 3 b7_hohh_age ## 4 b5_age ## 5 b9_hohh_marital_status ## 6 d1_hh_displacement_status ## 7 l4_which_difficult_access_health ## 8 j10_education_security_concerns_in_the_vicinity_of_facility ## 9 b7_hohh_age ## 10 b5_age ## 11 b9_hohh_marital_status ## 12 d1_hh_displacement_status ## 13 l4_which_difficult_access_health ## 14 j10_education_security_concerns_in_the_vicinity_of_facility ## 15 b7_hohh_age ## 16 b5_age ## 17 d1_hh_displacement_status ## dependent.variable.type independent.variable independent.variable.type ## 1 categorical strata categorical ## 2 categorical strata categorical ## 3 numerical strata categorical ## 4 numerical strata categorical ## 5 categorical strata categorical ## 6 categorical strata categorical ## 7 categorical &lt;NA&gt; &lt;NA&gt; ## 8 categorical &lt;NA&gt; &lt;NA&gt; ## 9 numerical &lt;NA&gt; &lt;NA&gt; ## 10 numerical &lt;NA&gt; &lt;NA&gt; ## 11 categorical &lt;NA&gt; &lt;NA&gt; ## 12 categorical &lt;NA&gt; &lt;NA&gt; ## 13 categorical b9_hohh_marital_status categorical ## 14 categorical b9_hohh_marital_status categorical ## 15 numerical b9_hohh_marital_status categorical ## 16 numerical b9_hohh_marital_status categorical ## 17 categorical b9_hohh_marital_status categorical ## hypothesis.type repeat.for.variable ## 1 group_difference &lt;NA&gt; ## 2 group_difference &lt;NA&gt; ## 3 group_difference &lt;NA&gt; ## 4 group_difference &lt;NA&gt; ## 5 group_difference &lt;NA&gt; ## 6 group_difference &lt;NA&gt; ## 7 direct_reporting &lt;NA&gt; ## 8 direct_reporting &lt;NA&gt; ## 9 direct_reporting &lt;NA&gt; ## 10 direct_reporting &lt;NA&gt; ## 11 direct_reporting &lt;NA&gt; ## 12 direct_reporting &lt;NA&gt; ## 13 group_difference strata ## 14 group_difference strata ## 15 group_difference strata ## 16 group_difference strata ## 17 group_difference strata To use a DAP, you need to use the function from_analysisplan_map_to_output instead of the combination of map_to_case and map_to_result. It will look for the case itself. from_analysisplan_map_to_output a list of list of results. So you need to wriggle a bit around to come to a master dataframe. my_results &lt;- hypegrammaR::from_analysisplan_map_to_output(data =main_dataset, analysisplan = my_dap, weighting = my_weigthing_function, questionnaire = my_questionnaire, confidence_level = .90) long_table &lt;- my_results$results %&gt;% lapply(function(x) x[[&quot;summary.statistic&quot;]]) %&gt;% do.call(rbind, .) long_table %&gt;% head() ## dependent.var independent.var dependent.var.value ## 1 l4_which_difficult_access_health strata lack_of_facilities ## 2 l4_which_difficult_access_health strata lack_of_facilities ## 3 l4_which_difficult_access_health strata lack_of_facilities ## 4 l4_which_difficult_access_health strata lack_of_facilities ## 5 l4_which_difficult_access_health strata cost_of_medicine ## 6 l4_which_difficult_access_health strata cost_of_medicine ## independent.var.value numbers se min max repeat.var ## 1 20km_rural 0.2131148 NA 0.15352034 0.2727092 &lt;NA&gt; ## 2 20km_urban 0.1013514 NA 0.05248276 0.1502199 &lt;NA&gt; ## 3 5km_rural 0.2500000 NA 0.19147544 0.3085246 &lt;NA&gt; ## 4 5km_urban 0.1160221 NA 0.06915872 0.1628855 &lt;NA&gt; ## 5 20km_rural 0.8579235 NA 0.80711592 0.9087311 &lt;NA&gt; ## 6 20km_urban 0.8378378 NA 0.77815151 0.8975242 &lt;NA&gt; ## repeat.var.value ## 1 &lt;NA&gt; ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; 5.2 srvyr package The srvyr package aims to add dplyr like syntax to the survey package. It is a very useful package for a variety of aggregations of survey data. ###makes some additions. library(tidyverse) library(butteR) library(srvyr) library(kableExtra) df&lt;-read_csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;) dfsvy&lt;-as_survey(df) 5.2.1 Categorical variables srvyr package allows categorical variables to be broken down using a similar syntax as dplyr. Using dplyr you might typically calculate a percent mean as follows: df %&gt;% group_by(b9_hohh_marital_status) %&gt;% summarise( n=n() ) %&gt;% ungroup() %&gt;% mutate( pct_mean=n/sum(n) ) ## # A tibble: 6 x 3 ## b9_hohh_marital_status n pct_mean ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 divorced 183 0.113 ## 2 married 677 0.419 ## 3 separated_married_but_not_living_together 37 0.0229 ## 4 single 129 0.0798 ## 5 unmarried_but_living_together 96 0.0594 ## 6 widowed 495 0.306 To calculate the percent mean of a categorical variable using srvyr object is required. The syntax is quite similar to dplyr, but a bit less verbose. By specifying the vartype as ci we also get the upper and lower confidence intervals dfsvy %&gt;% group_by(b9_hohh_marital_status) %&gt;% summarise( pct_mean = survey_mean(vartype = &quot;ci&quot;) ) ## # A tibble: 6 x 4 ## b9_hohh_marital_status pct_mean pct_mean_low pct_mean_upp ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 divorced 0.113 0.0977 0.129 ## 2 married 0.419 0.395 0.443 ## 3 separated_married_but_not_living_together 0.0229 0.0156 0.0302 ## 4 single 0.0798 0.0666 0.0930 ## 5 unmarried_but_living_together 0.0594 0.0478 0.0709 ## 6 widowed 0.306 0.284 0.329 5.2.2 Numeric variables srvyr treats the calculation/aggregation of numeric variables differently in an attempt to mirror dplyr syntax to calculate the mean and median expenditure in dplyr you would likely do the following df %&gt;% summarise( mean_expenditure= mean(n1_HH_total_expenditure,na.rm=T), median_expenditure=median(n1_HH_total_expenditure,na.rm=T), ) ## # A tibble: 1 x 2 ## mean_expenditure median_expenditure ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5129. 4000 If you wanted to subset this by another variable in dplyr you would add the group_by argument df %&gt;% group_by(strata) %&gt;% summarise( mean_expenditure= mean(n1_HH_total_expenditure,na.rm=T), median_expenditure=median(n1_HH_total_expenditure,na.rm=T), ) ## # A tibble: 4 x 3 ## strata mean_expenditure median_expenditure ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20km_rural 5488. 4000 ## 2 20km_urban 6208. 5000 ## 3 5km_rural 3919. 3075 ## 4 5km_urban 4942. 4000 This is the reason why the syntax also varies between categorical and numeric variables in srvyr. Therefore, to do the same using srvyr you would do the following (with a survey object). Note that due to this difference in syntax the na.rm argument works for numeric variables, but does not work for categorical variables. This was modified when srvyr was updated from v 0.3.8 dfsvy %&gt;% summarise( mean= survey_mean(n1_HH_total_expenditure,na.rm=T,vartype = &quot;ci&quot;), ) ## mean mean_low mean_upp ## 1 5128.962 4891.389 5366.536 similar to dplyr you can easily add a group_by argument to add a subset calculation dfsvy %&gt;% group_by(strata) %&gt;% summarise( mean= survey_mean(n1_HH_total_expenditure,na.rm=T,vartype = &quot;ci&quot;), ) ## # A tibble: 4 x 4 ## strata mean mean_low mean_upp ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20km_rural 5488. 4980. 5996. ## 2 20km_urban 6208. 5661. 6756. ## 3 5km_rural 3919. 3469. 4370. ## 4 5km_urban 4942. 4604. 5280. 5.3 butteR survey_collapse The survey_collapse function available in butteR aggregates both categorical and numerical columns of a srvyr object. It provides a standardized format output that includes mean/pct mean (point estimates), and the upper/lower confidence intervals along with the unweighted number/frequency for each response option. The survey_collapse function is built around the great srvyr package. The srvyr package is a more modern/tidyverse style wrapper for the survey package. Both the srvyr and survye packages are great and there use is highligh encouraged. The main advantages of survey_collapse The standardized output produced Ability to analyze both categorical and numerical columns with a consistent syntax Batch analyses and ability to perform many different subsetting investigations with ease Below is an example of its use. First we must read in some data and make it into a srvyr object ###makes some additions. library(tidyverse) library(butteR) library(srvyr) library(kableExtra) df&lt;-read_csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;) dfsvy&lt;-as_survey(df) For the purpose of the example I next choose a variety of different column types to analyze. As you can see I have selected select_one (categorical), select_multiple (binary categorical), and numerical columns. I then put these all into one vector. # here are some random concatenated select multiple parent questions select_multiple_parent_cols&lt;-c(&quot;l4_which_difficult_access_health&quot;, &quot;j10_education_security_concerns_in_the_vicinity_of_facility&quot;) numeric_cols&lt;- c(&quot;b7_hohh_age&quot;, &quot;b5_age&quot;) select_one_cols&lt;- c(&quot;b9_hohh_marital_status&quot;, &quot;d1_hh_displacement_status&quot;) mixed_columns&lt;- c(select_multiple_parent_cols, numeric_cols, select_one_cols) A nice feature of the standardized output produced by survey_collapse is that you can perform variety of different types of analyses and then bind them together into one dataframe/tibble. Therefore I fill an empty list with analysis to facilitate binding later. For the first analyses I simply aggregate all the columns specified as mean/pct mean. I next analyze the same variable but this time subset/disaggreated by the strata column. Its a good idea to mutate an extra column indicating what exact analysis was done so that when they are binded together later they can more easily be manipulated note: I am commenting this section as it seems to break with the latest update outputs&lt;-list() # outputs$overall&lt;-butteR::survey_collapse(df = dfsvy,vars_to_analyze = mixed_columns) %&gt;% # mutate(analysis_level= &quot;overall&quot;) # # outputs$strata&lt;-butteR::survey_collapse(df = dfsvy,vars_to_analyze = mixed_columns,disag = &quot;strata&quot;) %&gt;% # mutate(analysis_level= &quot;strata&quot;) Here is an example of what the long format data looks like as a table. This is a great format for manipulating/filtering and then graphing with ggplot # output_df&lt;- bind_rows(outputs) # # output_df %&gt;% # filter(analysis_level==&quot;overall&quot;) %&gt;% # mutate(question_val= paste0(variable,&quot;.&quot;,variable_val)) %&gt;% # ggplot(aes(x= question_val,y= `mean/pct`))+ # geom_point(stat=&quot;identity&quot;, position = position_dodge(width = 0.3))+ # geom_errorbar(aes(ymin= `mean/pct_low`, ymax= `mean/pct_upp`), # width=0.2,position = position_dodge(width = 0.3))+ # scale_y_continuous(labels = scales::percent,breaks = seq(0,1,by=0.1))+ # coord_flip()+ # theme_bw()+ # theme( # axis.title = element_blank(), # axis.text.x = element_text(angle=90), # legend.title= element_blank() # ) # # # # Easy to plot subset findings as well! # output_df %&gt;% # filter(analysis_level==&quot;strata&quot;) %&gt;% # mutate(question_val= paste0(variable,&quot;.&quot;,variable_val)) %&gt;% # ggplot(aes(x= question_val,y= `mean/pct`, color=subset_1_val))+ # geom_point(stat=&quot;identity&quot;, position = position_dodge(width = 0.3))+ # geom_errorbar(aes(ymin= `mean/pct_low`, ymax= `mean/pct_upp`), # width=0.2,position = position_dodge(width = 0.3))+ # scale_y_continuous(labels = scales::percent,breaks = seq(0,1,by=0.1))+ # coord_flip()+ # theme_bw()+ # theme( # axis.title = element_blank(), # axis.text.x = element_text(angle=90), # legend.title= element_blank() # ) 5.3.1 select_one 5.3.2 select_mutiple 5.4 Analysis with numerical variables 5.4.1 Averages ###Summarytools (CRAN package) ###hypegrammaR / koboquest / butteR 5.4.2 Median ####Spatstat Spatstat - library with set of different functions for analyzing Spatial Point Patterns but also quite useful for analysis of weighted data. At first lets select all numerical variables from the dataset using Kobo questionnaire and dataset. It can be done with the following custom function: select_numerical &lt;- function(dataset, kobo){ kobo_questions &lt;- kobo[grepl(&quot;integer|decimal|calculate&quot;, kobo$type),c(&quot;type&quot;,&quot;name&quot;)] names.use &lt;- names(dataset)[(names(dataset) %in% as.character(kobo_questions$name))] numerical &lt;- dataset[,c(names.use,&quot;X_uuid&quot;,&#39;strata&#39;,&#39;stratum.weight&#39;)] #Here we can select any other relevant variables numerical[names.use] &lt;- lapply(numerical[names.use], gsub, pattern = &#39;NA&#39;, replacement = NA) numerical[names.use] &lt;- lapply(numerical[names.use], as.numeric) return(numerical) } numerical_questions &lt;- select_numerical(main_dataset, questions) numerical_classes &lt;- sapply(numerical_questions[,1:c(ncol(numerical_questions)-3)], class) #Here we can check class of each selected variable numerical_classes &lt;- numerical_classes[&quot;character&quot; %in% numerical_classes] #and here we check if any variable has class &quot;character&quot; numerical_questions &lt;- numerical_questions[ , !names(numerical_questions) %in% numerical_classes] #if any variable has a character class then we remove it rm(numerical_classes)#and here we removing vector with classes from our environment Now lets calculate weighted median for n1_HH_total_expenditure. weighted.median(numerical_questions$n1_HH_total_expenditure, numerical_questions$stratum.weight, na.rm=TRUE) ## [1] 4119.113 But if we want to calculate weighted medians for each variable we will need to iterate this function on those variables. But first we will need to exclude variables with less than 3 observations. counts &lt;- numerical_questions %&gt;% select(-X_uuid, -strata) %&gt;% summarise(across(.cols = everything(), .fns= ~sum(!is.na(.)) ))%&gt;% t()#Calculating count of observation for each variable numerical_questions &lt;- numerical_questions[ , (names(numerical_questions) %in% rownames(subset(counts, counts[,1] &gt; 3)))] #removing variables with less than 3 observations medians &lt;- lapply(numerical_questions[1:46], weighted.median, w = numerical_questions$stratum.weight, na.rm=TRUE)%&gt;% as.data.frame() Now we can transpond resulting vector and add description to the calculation medians &lt;- as.data.frame(t(medians),stringsAsFactors = FALSE) names(medians)[1] &lt;- &quot;Median_wght&quot; head(medians) ## Median_wght ## b15_hohh_income 2800 ## hohh_age_18 0 ## age_18 0 ## b21_num_additional_hh_members 1 ## age_5_18_number 0 ## age_5_12_number 0 5.5 Weights surveyweights survey (CRAN package) srvyr (CRAN package) 5.6 Repeating the above 5.7 Top 3 5.8 Borda count 5.9 Hypothesis testing 5.9.1 T-test 5.9.2 ANOVA 5.9.3 chi-squares "]]
