# Data Collection and Processing
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
library(magrittr)
library(dplyr)
library(kableExtra)
library(readxl)

main_dataset <- read.csv("inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv", na.strings = "")

questions <- read_xlsx("inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx",sheet="survey")
choices <- read_xlsx("inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx",sheet="choices")
```

```{r, tidy=FALSE, eval = F}
#** un-comment those if you need them to be installed
# devtools::install_github("https://github.com/impact-initiatives/xlsformfill/")
# devtools::install_github("https://github.com/impact-initiatives/cleaninginspectoR/")
```

*
Notes on **cleaninginspectoR**:
- The function will return a dataframe with indexes not the uuid.
- cleanninginspectoR uses function from the **magrittr** and **dplyr** packages. Don't forget to load them before using it.
*

## Testing the tool

### Creating dummy data

**xlsformfill** has a function **xlsform_fill** that will create dataset based on your KOBO questionnaire. It takes 3 arguments: your questions, your choices and how many rows you want.

*Notes:
- All questions will be filled. 
- Skip logic are not implemented.
- Constraints are not implemented.
- Integers and text will be generated randomly
*
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
dummy_dataset <- xlsformfill::xlsform_fill(questions = questions, choices = choices, n = 300)
```
```{r, tidy=FALSE, eval = F}
dummy_dataset %>% head(10)
```
```{r, echo =F, message= F, warning=F,}
dummy_dataset  %>% 
  head(10) %>%
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

## Download data

### download from API 

koboapi
koboloadeR 
kobohr_apitoolbox

## Data collection follow-up

### checking surveys against sampling frame

## Data falsification

### Check for time (in the dataset)
lubridate
Custom script

### Check for time (audit files)	
Custom script (using ???)

### Silouhette analysis	
Custom script (using ???)

### Check for duplicates	
#### cleaninginspectoR - find_duplicates

**find_duplicates** will take the dataset and a column name to look for duplicates as arguments.

```{r, tidy=FALSE, message= F, warning=F, error=F}
cleaninginspectoR::find_duplicates(main_dataset, duplicate.column.name = "X_uuid")

dummy_dataset[301, ] <- dummy_dataset[300, ]
cleaninginspectoR::find_duplicates(dummy_dataset, duplicate.column.name = "uuid")
```
```{r, tidy=FALSE, message= F, warning=F, error=F}
cleaninginspectoR::find_duplicates(dummy_dataset, duplicate.column.name = "start")
```

#### base - duplicated

If you are looking in duplicates value in several columns (first and second name, names and ID number,etc.), you can use the **duplicated**. 

```{r, tidy=T}
dummy_test <- data.frame(col_a = c("a", "a", "c"), 
                         col_b = c("b", "b", "f"))
dummy_test
```
Rows 1 and 2 are duplications. 
```{r, tidy=FALSE, message= F, warning=F, error=F}
duplicated(dummy_test)
```

**find_duplicates()** and **duplicated()** functions will return position or value **only of one** duplicated record. But after identification of the duplicate, it will be good to check how many of such duplicated records in the dataset and check if they have any other duplicated columns. Based on your investigation, you will need to delete one or several records. e.g. Enumerator submitted the first survey by mistake and after some time submitted a corrected survey with the same id (in case we allow for the enumerator to select the id of the enterprise or sample). In such a way, find_duplicates() will identify the second survey but we will need to delete the first one.


#### Find most similar surveys

The function **find_similar_surveys()** compares each survey with each other survey in the dataset and finds the most similar one, i.e., the one with the lowest number of different answers. The function uses the gower matrix to make the comparison more efficient. The function returns a dataframe with the same number of rows (all surveys) and a few additional columns indicating the ID of the most similar survey and how many columns are different.

Depending on the size of the questionnaire and on the data collection methodology, we can set a maximum threshold on the number of differences and follow up on all the surveys that have a matching survey with a lower number of differences than the threshold. For example, in the MSNA in Syria, we used a maximum threshold of 7 differences.

In the version below, the function uses only the data from the main sheet of the survey. If the tools includes loop(s), it makes sense to add a few relevant columns from the loops to the main dataframe so that they are also used in the search of the most similar survey. For example, for an HH survey with a loop for the HH composition, one can add to the main dataframe one column with the concatenation of the genders of the HH components and one column with the concatenation of the ages of the HH components (from the loop).

```{r, eval=F}
find_similar_surveys <- function(raw.data, tool.survey, uuid="_uuid"){
  # 1) store UUIDs
  uuids <- raw.data[[uuid]]
  
  # 2) convert all columns to character and tolower
  raw.data <- mutate_all(raw.data, as.character)
  raw.data <- mutate_all(raw.data, tolower)
  
  # 3) remove columns that are naturally different in each survey:
  # - columns of type = "start", "end", "text" (for the other responses), etc.
  # - columns starting with "_"
  # - option columns for the select multiple -> keeping only the concatenation column
  types_to_remove <- c("start", "end", "today", "deviceid", "date", "geopoint", "audit", 
                       "note", "calculate", "text")
  cols_to_keep <- data.frame(column=colnames(raw.data)) %>% 
    left_join(select(tool.survey, name, type), by=c("column"="name")) %>% 
    filter(!(type %in% types_to_remove) & !str_starts(column, "_") & !str_detect(column, "/"))
  raw.data <- raw.data[, all_of(cols$column)]
  
  # 4) remove columns with all NA; convert remaining NA to "NA"; convert all columns to factor
  raw.data <- raw.data[, colSums(is.na(raw.data))<nrow(raw.data)]
  raw.data[is.na(raw.data)] <- "NA"
  raw.data <- raw.data %>% mutate_if(is.character, factor)
  error.message <- "NAs detected, remove them before proceeding (it can happen when converting to factor)"
  if (sum(is.na(raw.data))>0) stop(error.message)
  
  # 5) calculate gower distance
  gower_dist <- daisy(raw.data, metric="gower", warnBin=F, warnAsym=F, warnConst=F)
  gower_mat <- as.matrix(gower_dist)
  
  # 6) convert distance to number of differences and determine closest matching survey
  r <- unlist(lapply(1:nrow(raw.data), function(i) sort(gower_mat[i,]*ncol(raw.data))[2]))
  
  # 7) add relevant columns
  raw.data[["num_cols_not_NA"]] <- rowSums(raw.data!="NA")
  raw.data[[uuid]] <- uuids
  raw.data[["_id_most_similar_survey"]] <- uuids[as.numeric(names(r))]
  raw.data[["number_different_columns"]] <- as.numeric(r)
  raw.data <- raw.data %>% arrange(number_different_columns, uuid)
  
  return(raw.data)
}
```


##	Data checks	
### Check for outliers	
There are 2 commons ways to detect outliers :

- Using the range of 3 standards deviations from the mean. 
- Using the range of 1.5 inter quartile from the 1st and 3rd quartile. 

Outliers can exist but it is important to check them.

#### cleaninginspectoR - find_outliers
The function find_outliers will use the rule of the 3 standards deviations from the mean for normal values and log values. 

```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
cleaning_log <- cleaninginspectoR::find_outliers(main_dataset)
```
```{r, tidy=FALSE, eval = F}
cleaning_log %>% head(20)
```
```{r, echo =F, message= F, warning=F,}
cleaning_log  %>% 
  head(20) %>%
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

###	Check others
#### cleaninginspectoR - find_other_responses

**find_other_responses** will look for all columns with "other", "Other", "autre", "Autre",  and return their values.

*Notes:
- If your *other* questions do not have those 4 strings in their names, the function will not pick it.
*
```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
cleaning_log <- cleaninginspectoR::find_other_responses(main_dataset)
```
```{r, tidy=FALSE, eval = F}
cleaning_log %>% head(10)
```
```{r, echo =F, message= F, warning=F,}
cleaning_log  %>% 
  head(10) %>%
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

#### base + dplyr

This example will take all the text type from the questionnaire, filter for the ones that are in the dataset and return all the values. 
```{r, tidy=FALSE, echo=T}
oth <- questions$name[questions$type == "text"]
oth <- oth[oth %in% names(main_dataset)]
oth_log <- oth %>% 
  lapply(function(x) {
    main_dataset %>% 
      select("X_uuid", !!sym(x)) %>% 
      filter(!is.na(!!sym(x))) %>%
      as.data.frame() %>% 
      mutate(col_names = x) %>%
      rename(other_text = !!sym(x)) %>%
      arrange(other_text)}) %>% 
  do.call(rbind,.)
```
```{r, tidy=FALSE, eval = F}
oth_log %>% head(20)
```
```{r, echo =F, message= F, warning=F,}
oth_log  %>% 
  head(20) %>%
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

*Please note that it takes the values as they are. You may want to trim and remove caps or any other regex work if you want better summary *

This other example looks at the frequency of a given *other* option, it could be used to see if some should be recoded as options directly.

```{r, tidy=FALSE, message= F, warning=F, error=F, echo=T}
oth_prop <- oth %>% 
  lapply(function(x) {
    main_dataset %>% 
      select(!!sym(x)) %>% 
      table() %>% 
      as.data.frame() %>% 
      # rename(other_text = `.`) %>%
      arrange(`.`) %>% 
      mutate(col_names = x, 
             prop = Freq/nrow(main_dataset))
  }) %>%
  do.call(rbind,.)
```
```{r, tidy=FALSE, eval = F}
oth_prop %>% head(20)
```
```{r, echo =F, message= F, warning=F,}
oth_prop  %>% 
  head(20) %>%
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```


###	Check for logical check	
hum hum hum ?? 
Custom script (using dplyr?)
		
- Any value that is arbitrary set (from an informed source e.g. an informal setttlement cannot be lower than 15 households). This type of outliers could also be considered as logical checks.

## cleaninginspectoR - inspect_all

cleanninginspectoR has a function inspect *inspect_all* that will look for outliers, others responses that may need recoding, duplicated uuid and possible sensitive columns. It takes as arguments the dataset and the uuid column name. 
```{r, tidy=FALSE, message= F, warning=F, error=F}
cleaning_log <- cleaninginspectoR::inspect_all(main_dataset, "X_uuid")
```
```{r, tidy=FALSE, eval = F}
cleaning_log %>% head(20)
```
```{r, echo =F, message= F, warning=F,}
cleaning_log  %>% 
  head(20) %>%
  kable() %>% 
  kable_styling(font_size=8) %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```

## Data cleaning		
### Clean data base on cleaning log	
clog
butteR

### Check cleaning log, raw dataset and clean dataset	
dplyr
waldo 
arsenal

## Data cleaning - miscellaneous		
###	Check for data sanity	check if the data follow ODK format (select_one, select_multiple, xxx, choices)
To be created

###	Turns label to xml	
Custom script (using ???)

###	Statistical Disclosure Control Methods	
sdcMicro







