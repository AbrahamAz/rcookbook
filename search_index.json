[["index.html", "R cookbook for analysis with REACH 1 Hello World", " R cookbook for analysis with REACH R CoP 1 Hello World Hi. Bye. "],["meta-information.html", "2 Meta information 2.1 Creating the questionnaire object", " 2 Meta information There should be here the libraries, dataset, odk and sampling frame and any other thing. ## Importing dataset and questionnaire library(magrittr) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(readxl) library(hypegrammaR) ## Loading required package: survey ## Loading required package: grid ## Loading required package: Matrix ## Loading required package: survival ## ## Attaching package: &#39;survey&#39; ## The following object is masked from &#39;package:graphics&#39;: ## ## dotchart ## Loading required package: ggplot2 ## Loading required package: ggthemes ## Loading required package: tidyr ## ## Attaching package: &#39;tidyr&#39; ## The following objects are masked from &#39;package:Matrix&#39;: ## ## expand, pack, unpack ## The following object is masked from &#39;package:magrittr&#39;: ## ## extract ## Loading required package: crayon ## ## Attaching package: &#39;crayon&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## %+% main_dataset &lt;- read.csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;, na.strings = &quot;&quot;) loop_dataset &lt;- read.csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_loop_rcop.csv&quot;, na.strings = &quot;&quot;) questions &lt;- read_xlsx(&quot;inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx&quot;,sheet=&quot;survey&quot;) ## New names: ## * `` -&gt; ...19 ## * `` -&gt; ...20 ## * `` -&gt; ...21 ## * `` -&gt; ...22 ## * `` -&gt; ...23 choices &lt;- read_xlsx(&quot;inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx&quot;,sheet=&quot;choices&quot;) Note that some variables were NAed (age, etc.) In addition, it seems the weights are already added, and both loops where combined already. 2.1 Creating the questionnaire object main_dataset &lt;- main_dataset %&gt;% select_if(~ !(all(is.na(.x)) | all(. == &quot;&quot;))) questionnaire &lt;- load_questionnaire(data = main_dataset, questions = questions, choices = choices, choices.label.column.to.use = &quot;label::English&quot;) Probably which packages are used and version "],["cleaning.html", "3 Cleaning 3.1 Custom packages with cleaning functions 3.2 Example one 3.3 Example two", " 3 Cleaning 3.1 Custom packages with cleaning functions kobold/ butteR/ auditCheckR 3.2 Example one 3.3 Example two "],["composite-indicators.html", "4 Composite indicators 4.1 Composite with 1 categorical variable - select one 4.2 Composite with 2 categorical variables 4.3 Composite with 1 categorical variable - select multiple 4.4 Composite with 1 numerical variable 4.5 Composite with 2 numerical variables 4.6 Composite with 2 or more numerical variables 4.7 New indicators from a loop to main dataset", " 4 Composite indicators composeR dplyr::case_when 4.1 Composite with 1 categorical variable - select one This example will look at creating an improved source of water variable. The indicator of interest is f11_dinking_water_source and the options for un-improved source of water are: trucked_in_water_truck_with_a_tank_etc drinking_water_from_water_kiosk_booth_with_water_for_bottling bottled_water_water_purchased_in_bottles other_specify #Creating a vector of un-improved source of water unimproved_source &lt;- c(&quot;trucked_in_water_truck_with_a_tank_etc&quot;, &quot;drinking_water_from_water_kiosk_booth_with_water_for_bottling&quot;, &quot;bottled_water_water_purchased_in_bottles&quot;, &quot;other_specify&quot;) #Using base R main_dataset$wash_drinkingwater_improved_source_baser &lt;- ifelse(main_dataset$f11_dinking_water_source %in% unimproved_source, &quot;not_improved&quot;, &quot;improved&quot;) table(main_dataset$f11_dinking_water_source, main_dataset$wash_drinkingwater_improved_source_baser, useNA = &quot;ifany&quot;) ## ## improved ## bottled_water_water_purchased_in_bottles 0 ## drinking_water_from_water_kiosk_booth_with_water_for_bottling 0 ## other_specify 0 ## personal_well 414 ## public_well_or_boreholes_shared_access 187 ## tap_drinking_water_centralized_water_supply 479 ## technical_piped_water 2 ## trucked_in_water_truck_with_a_tank_etc 0 ## ## not_improved ## bottled_water_water_purchased_in_bottles 68 ## drinking_water_from_water_kiosk_booth_with_water_for_bottling 366 ## other_specify 11 ## personal_well 0 ## public_well_or_boreholes_shared_access 0 ## tap_drinking_water_centralized_water_supply 0 ## technical_piped_water 0 ## trucked_in_water_truck_with_a_tank_etc 90 #Using base R main_dataset$wash_drinkingwater_improved_source_baser2 &lt;- NA main_dataset$wash_drinkingwater_improved_source_baser2[main_dataset$f11_dinking_water_source %in% unimproved_source] &lt;- &quot;not_improved&quot; main_dataset$wash_drinkingwater_improved_source_baser2[!(main_dataset$f11_dinking_water_source %in% unimproved_source)] &lt;- &quot;improved&quot; #Same same table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_drinkingwater_improved_source_baser2, useNA = &quot;ifany&quot;) ## ## improved not_improved ## improved 1082 0 ## not_improved 0 535 #Using case_when main_dataset &lt;- main_dataset %&gt;% mutate(wash_improved_source_dplyr = case_when(f11_dinking_water_source %in% unimproved_source ~ &quot;not_improved&quot;, TRUE ~ &quot;improved&quot;)) table(main_dataset$f11_dinking_water_source, main_dataset$wash_improved_source_dplyr, useNA = &quot;ifany&quot;) ## ## improved ## bottled_water_water_purchased_in_bottles 0 ## drinking_water_from_water_kiosk_booth_with_water_for_bottling 0 ## other_specify 0 ## personal_well 414 ## public_well_or_boreholes_shared_access 187 ## tap_drinking_water_centralized_water_supply 479 ## technical_piped_water 2 ## trucked_in_water_truck_with_a_tank_etc 0 ## ## not_improved ## bottled_water_water_purchased_in_bottles 68 ## drinking_water_from_water_kiosk_booth_with_water_for_bottling 366 ## other_specify 11 ## personal_well 0 ## public_well_or_boreholes_shared_access 0 ## tap_drinking_water_centralized_water_supply 0 ## technical_piped_water 0 ## trucked_in_water_truck_with_a_tank_etc 90 #Same same table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_improved_source_dplyr) ## ## improved not_improved ## improved 1082 0 ## not_improved 0 535 In the previous example, there was no missing value. For this example, the indicator to be built will turn a yes/no question into a dummy variable (1 and 0). The variable of interest is b16_hohh_pension_eligible table(main_dataset$b16_hohh_pension_eligible, useNA = &quot;ifany&quot;) ## ## no yes &lt;NA&gt; ## 6 870 741 #Using base R main_dataset$hohh_pension_eligible_dummy_baser &lt;- ifelse(main_dataset$b16_hohh_pension_eligible == &quot;yes&quot;, 1, 0) table(main_dataset$b16_hohh_pension_eligible, main_dataset$hohh_pension_eligible_dummy_baser, useNA = &quot;ifany&quot;) ## ## 0 1 &lt;NA&gt; ## no 6 0 0 ## yes 0 870 0 ## &lt;NA&gt; 0 0 741 #Using case_when main_dataset &lt;- main_dataset %&gt;% mutate(hohh_pension_eligible_dummy_dplyr = case_when(b16_hohh_pension_eligible == &quot;yes&quot; ~ 1, b16_hohh_pension_eligible == &quot;no&quot; ~ 0)) table(main_dataset$b16_hohh_pension_eligible, main_dataset$hohh_pension_eligible_dummy_dplyr, useNA = &quot;ifany&quot;) ## ## 0 1 &lt;NA&gt; ## no 6 0 0 ## yes 0 870 0 ## &lt;NA&gt; 0 0 741 #Same same table(main_dataset$hohh_pension_eligible_dummy_baser, main_dataset$hohh_pension_eligible_dummy_dplyr, useNA = &quot;ifany&quot;) ## ## 0 1 &lt;NA&gt; ## 0 6 0 0 ## 1 0 870 0 ## &lt;NA&gt; 0 0 741 #Watch out for NA. This was is not correct. main_dataset &lt;- main_dataset %&gt;% mutate(hohh_pension_eligible_dummy_dplyr2 = case_when(b16_hohh_pension_eligible == &quot;yes&quot; ~ 1, TRUE ~ 0)) table(main_dataset$b16_hohh_pension_eligible, main_dataset$hohh_pension_eligible_dummy_dplyr2, useNA = &quot;ifany&quot;) ## ## 0 1 ## no 6 0 ## yes 0 870 ## &lt;NA&gt; 741 0 #Not same same table(main_dataset$hohh_pension_eligible_dummy_baser, main_dataset$hohh_pension_eligible_dummy_dplyr2, useNA = &quot;ifany&quot;) ## ## 0 1 ## 0 6 0 ## 1 0 870 ## &lt;NA&gt; 741 0 4.2 Composite with 2 categorical variables This example will look at creating an indicator whether or not the sources for drinking and for cooking, cleaning and non-drinking purposes are both improved. The indicators of interest are f11_dinking_water_source (and more specifically wash_drinkingwater_improved_source_baser from previous paragraph) and f14_technical_water_source (F14_What is your HHs main source of water for cooking, cleaning, and non-drinking purposes). First, a new variable has to be created, wash_otherwater_improved_source_baser. #Using base R main_dataset$wash_otherwater_improved_source_baser &lt;- ifelse(main_dataset$f14_technical_water_source %in% unimproved_source, &quot;not_improved&quot;, &quot;improved&quot;) main_dataset$wash_bothwater_improved_source_baser &lt;- ifelse(main_dataset$wash_drinkingwater_improved_source_baser == &quot;improved&quot; &amp; main_dataset$wash_otherwater_improved_source_baser == &quot;improved&quot;, &quot;both_improved&quot;, &quot;not_both_improved&quot;) table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_otherwater_improved_source_baser, main_dataset$wash_bothwater_improved_source_baser, useNA = &quot;ifany&quot;) ## , , = both_improved ## ## ## improved not_improved ## improved 1074 0 ## not_improved 0 0 ## ## , , = not_both_improved ## ## ## improved not_improved ## improved 0 8 ## not_improved 480 55 Now, the variable will be coded to have 3 categories instead: both improved, at least drinking water and not improved. main_dataset$wash_bothwater_improved_source_baser2 &lt;- ifelse(main_dataset$wash_drinkingwater_improved_source_baser == &quot;improved&quot; &amp; main_dataset$wash_otherwater_improved_source_baser == &quot;improved&quot;, &quot;both_improved&quot;, ifelse(main_dataset$wash_drinkingwater_improved_source_baser == &quot;improved&quot;, &quot;at_least_drinking&quot;, &quot;not_both_improved&quot;)) table(main_dataset$wash_drinkingwater_improved_source_baser, main_dataset$wash_otherwater_improved_source_baser, main_dataset$wash_bothwater_improved_source_baser2, useNA = &quot;ifany&quot;) ## , , = at_least_drinking ## ## ## improved not_improved ## improved 0 8 ## not_improved 0 0 ## ## , , = both_improved ## ## ## improved not_improved ## improved 1074 0 ## not_improved 0 0 ## ## , , = not_both_improved ## ## ## improved not_improved ## improved 0 0 ## not_improved 480 55 #Using dplyr main_dataset &lt;- main_dataset %&gt;% mutate(wash_bothwater_improved_source_dplyr = case_when(wash_drinkingwater_improved_source_baser == &quot;improved&quot; &amp; wash_otherwater_improved_source_baser == &quot;improved&quot; ~ &quot;both_improved&quot;, wash_drinkingwater_improved_source_baser == &quot;improved&quot; ~ &quot;at_least_drinking&quot;, TRUE ~ &quot;not_both_improved&quot; )) table(main_dataset$wash_bothwater_improved_source_dplyr, main_dataset$wash_bothwater_improved_source_baser2, useNA = &quot;ifany&quot;) ## ## at_least_drinking both_improved not_both_improved ## at_least_drinking 8 0 0 ## both_improved 0 1074 0 ## not_both_improved 0 0 535 4.3 Composite with 1 categorical variable - select multiple e.g. improved source of water # main_dataset &lt;- main_dataset %&gt;% # mutate(case_when XXXX) 4.4 Composite with 1 numerical variable This example will look at creating one a categorical variable based on a number, f6_how_many_wood_hh_consumed_last_winter , less than 5, between 5 (included) and 10 and 10 and above. main_dataset &lt;- main_dataset %&gt;% mutate(wood_consumed_categories = case_when(f6_how_many_wood_hh_consumed_last_winter &lt; 5 ~ &quot;less_than_5&quot;, f6_how_many_wood_hh_consumed_last_winter &lt; 10 ~ &quot;between5_and10&quot;, f6_how_many_wood_hh_consumed_last_winter &gt;= 10 ~ &quot;ten_above&quot;)) 4.5 Composite with 2 numerical variables This example will look at creating one of the indicators necessary to compute the FCS. In some cases, we need to check if the sum of number of days for 2 types of food are above 7 or not. If the sum is above 7, then it has to return 7 otherwise, the sum of both variables. # Combine cereals/roots and meat/eggs and make maximum 7 days ## Using base R main_dataset$fcs_cereal_roots &lt;- ifelse((main_dataset$g1_cereals_consumption + main_dataset$g2_roots_consumption) &gt; 7, 7, main_dataset$g1_cereals_consumption + main_dataset$g2_roots_consumption) ## Using dplyr main_dataset &lt;- main_dataset %&gt;% mutate(fcs_meat_eggs = ifelse((g5_meat_consumption + g6_eggs_consumption) &gt; 7, 7, g5_meat_consumption + g6_eggs_consumption)) 4.6 Composite with 2 or more numerical variables This example will look at creating the food consumption score. main_dataset &lt;- main_dataset %&gt;% mutate(FCS_score_dplyr = fcs_cereal_roots * 2 + g3_vegetables_consumption * 1 + g4_fruits_consumption * 1 + fcs_meat_eggs * 4 + g7_pulses_consumption * 3 + g8_dairy_consumption * 4 + g9_oil_consumption * 0.5 + g10_sugar_consumption * 0.5) main_dataset$FCS_score_baser &lt;- (main_dataset$fcs_cereal_roots * 2)+ (main_dataset$g3_vegetables_consumption * 1)+ (main_dataset$g4_fruits_consumption * 1)+ (main_dataset$fcs_meat_eggs * 4)+ (main_dataset$g7_pulses_consumption * 3)+ (main_dataset$g8_dairy_consumption * 4)+ (main_dataset$g9_oil_consumption * 0.5)+ (main_dataset$g10_sugar_consumption * 0.5) 4.7 New indicators from a loop to main dataset e.g. aggregating the number of children going to school from a loop "],["analysis.html", "5 Analysis 5.1 hypegrammaR 5.2 srvyr package 5.3 butteR survey_collapse 5.4 Analysis with numerical variables 5.5 Weights 5.6 Repeating the above 5.7 Top 3 5.8 Borda count 5.9 Hypothesis testing", " 5 Analysis 5.1 hypegrammaR hypegrammaR follow the case mapping logic to compute analysis. It will also use the kobo questionnaire tool to help some of decision to be made. This just load the information that will be need to conduct the analysis : dataset, kobotool (questions and choices), sample frame library(hypegrammaR) library(magrittr) library(surveyweights) library(srvyr) library(readxl) #load dataset main_dataset &lt;- read.csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;, na.strings = &quot;&quot;) #load kobotool questions &lt;- read_xlsx(&quot;inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx&quot;,sheet=&quot;survey&quot;) choices &lt;- read_xlsx(&quot;inputs/UKR2007_MSNA20_HH_Questionnaire_24JUL2020.xlsx&quot;,sheet=&quot;choices&quot;) #load sampling frame my_sampling_frame &lt;- read_excel(&quot;inputs/UKR2007_MSNA20_GCA_Weights_26AUG2020.xlsx&quot;, sheet = &quot;for_r&quot;) The questionnaire object is a list of function using the kobotool and dataset as input. For example, it will check if a given variable is a select multiple or not. #create a questionnaire object my_questionnaire &lt;- hypegrammaR::load_questionnaire(data = main_dataset, questions = questions, choices = choices, choices.label.column.to.use = &quot;label::English&quot;) The weighting function is created by the weighting_fun_from_samplinframe from the surveyweights package. It calculates the design weight based on the sampling frame and the dataset. The stratification names values used in the sampling frame and the dataset HAS to be the same. What it does, it create a function that will calculate the weights based on your dataset. (It was defined as a function so it could re-calculate weights depending on the subset. however, the current guidelines is to keep the same design weights through all the assessement; the function still works for that case) #create a weigthing function my_weigthing_function &lt;- surveyweights::weighting_fun_from_samplingframe(sampling.frame = my_sampling_frame, data.stratum.column = &quot;strata&quot;, sampling.frame.population.column = &quot;population&quot;, sampling.frame.stratum.column = &quot;strata&quot;, data = main_dataset) If you want to add the weights to your dataframe this is how you can do it. #optional, if you want to add the weights into the dataset. main_dataset$stratum.weight &lt;- my_weigthing_function(main_dataset) hypegrammaR uses cases to choose what type analysis to do. A case for hypegrammaR is a character string CASE_XXXX_YYYY_ZZZZ where : XXXX: hypothesis type (group_difference, direct_reporting) YYYY: dependent var type (categorical, numerical) ZZZZ: independent var type (categorical, numerical, empty if no independent variable) . All cases implemented can been seen with this code. hypegrammaR:::list_all_cases(implemented_only = T) ## [1] &quot;CASE_group_difference_categorical_categorical&quot; ## [2] &quot;CASE_group_difference_numerical_categorical&quot; ## [3] &quot;CASE_direct_reporting_numerical_&quot; ## [4] &quot;CASE_direct_reporting_categorical_&quot; ## [5] &quot;CASE_direct_reporting_categorical_categorical&quot; ## [6] &quot;CASE_direct_reporting_numerical_categorical&quot; ## [7] &quot;CASE_limit_categorical&quot; ## [8] &quot;CASE_limit_numerical&quot; ## [9] &quot;CASE_correlation_numerical_numerical&quot; ## [10] &quot;CASE_correlation_categorical_numerical&quot; If you want to know what are the different proportion of the displacement status for each strata. The following information I need are: hypothesis : group_difference dependent variable : d1_hh_displacement_status -&gt; categorical independent_variable : strata -&gt; categorical #analysis my_case &lt;- hypegrammaR::map_to_case(hypothesis.type = &quot;group_difference&quot;, dependent.var.type = &quot;categorical&quot;, independent.var.type = &quot;categorical&quot;) my_case ## [1] &quot;CASE_group_difference_categorical_categorical&quot; ## attr(,&quot;class&quot;) ## [1] &quot;analysis_case&quot; The function map_to_result will calculate your summary statistics, it will take a couple of arguments. my_results &lt;- hypegrammaR::map_to_result(data = main_dataset, dependent.var = &quot;d1_hh_displacement_status&quot;, independent.var = &quot;strata&quot;, case = my_case, weighting = my_weigthing_function, questionnaire = my_questionnaire, confidence_level = .90) The result object is a list with several information: parameters: returns the information used of that analysis summary statistics: returns the summary statistics in a tidy format hypothesis test: returns hypothesis testing information (if avalaible) message: returns a message (if the analysis went well or not) my_results$summary.statistic %&gt;% head() ## dependent.var independent.var ## 1 d1_hh_displacement_status strata ## 2 d1_hh_displacement_status strata ## 3 d1_hh_displacement_status strata ## 4 d1_hh_displacement_status strata ## 5 d1_hh_displacement_status strata ## 6 d1_hh_displacement_status strata ## dependent.var.value ## 1 displaced_and_idp_status ## 2 displaced_but_does_not_have_idp_status ## 3 no ## 4 partially_displaced_and_dont_have_idp_status ## 5 partially_displaced_and_have_idp_status ## 6 used_to_be_displaced_but_returned_and_has_no_status_of_idp ## independent.var.value numbers se min max ## 1 20km_rural 0.046683047 NA 0.0261473551 0.067218738 ## 2 20km_rural 0.002457002 NA -0.0023622501 0.007276255 ## 3 20km_rural 0.911547912 NA 0.8839068400 0.939188983 ## 4 20km_rural 0.007371007 NA -0.0009555979 0.015697613 ## 5 20km_rural 0.022113022 NA 0.0077984141 0.036427630 ## 6 20km_rural 0.009828010 NA 0.0002251810 0.019430839 If you need to run several analysis, you can use a data analysis plan (DAP) file which is a file that comprises of the following columns: dependent.variable: name of the dependent variable (kobo name, column name) dependent.variable.type: type of the dependent variable (categorical or numerical or empty) independent.variable: name of the independent variable (kobo name, column name) independent.variable.type: type of the independent variable (categorical or numerical or empty) repeat.for.variable: name of the variable to repeat the analysis for (e.g per camp or district or governorate) hypothesis.type: type of hypothesis (group_difference, direct_reporting) you can have other columns to help you write the analysis plan such as RQ and sub RQ You cannot have duplicate columns Below, I am creating the DAP, but you could read a csv file. It has : 2 categorical variables, (select multiple type in kobo), l4_which_difficult_access_health and j10_education_security_concerns_in_the_vicinity_of_facility 2 categorical variables, (select one type in kobo), b9_hohh_marital_status and d1_hh_displacement_status, 2 numerical variables (integer type in kobo): b7_hohh_age and b5_age It will repeat the analysis 3 times for each dependent variable: using the strata variable as independent variable (first 6 rows), using no independent variable, for the complete dataset (national level?), (second 6 rows), using the b9_hohh_marital_status as independent variable but repeating each strata (last 6 rows) #dap my_dap &lt;- data.frame(dependent.variable = c(rep(c(&quot;l4_which_difficult_access_health&quot;, &quot;j10_education_security_concerns_in_the_vicinity_of_facility&quot;, &quot;b7_hohh_age&quot;, &quot;b5_age&quot;, &quot;b9_hohh_marital_status&quot;, &quot;d1_hh_displacement_status&quot;), 2), c(&quot;l4_which_difficult_access_health&quot;, &quot;j10_education_security_concerns_in_the_vicinity_of_facility&quot;, &quot;b7_hohh_age&quot;, &quot;b5_age&quot;, &quot;d1_hh_displacement_status&quot;)), dependent.variable.type = c(rep(c(&quot;categorical&quot;, &quot;categorical&quot;, &quot;numerical&quot;, &quot;numerical&quot;, &quot;categorical&quot;, &quot;categorical&quot;),2),&quot;categorical&quot;, &quot;categorical&quot;, &quot;numerical&quot;, &quot;numerical&quot;, &quot;categorical&quot;), independent.variable = c(rep(&quot;strata&quot;, 6), rep(NA, 6), rep(&quot;b9_hohh_marital_status&quot;, 5)), independent.variable.type = c(rep(&quot;categorical&quot;, 6), rep(NA, 6), rep(&quot;categorical&quot;, 5)), hypothesis.type = c(rep(&quot;group_difference&quot;, 6), rep(&quot;direct_reporting&quot;, 6), rep(&quot;group_difference&quot;, 5)), repeat.for.variable = c(rep(NA, 12), rep(&quot;strata&quot;, 5)) ) my_dap ## dependent.variable ## 1 l4_which_difficult_access_health ## 2 j10_education_security_concerns_in_the_vicinity_of_facility ## 3 b7_hohh_age ## 4 b5_age ## 5 b9_hohh_marital_status ## 6 d1_hh_displacement_status ## 7 l4_which_difficult_access_health ## 8 j10_education_security_concerns_in_the_vicinity_of_facility ## 9 b7_hohh_age ## 10 b5_age ## 11 b9_hohh_marital_status ## 12 d1_hh_displacement_status ## 13 l4_which_difficult_access_health ## 14 j10_education_security_concerns_in_the_vicinity_of_facility ## 15 b7_hohh_age ## 16 b5_age ## 17 d1_hh_displacement_status ## dependent.variable.type independent.variable independent.variable.type ## 1 categorical strata categorical ## 2 categorical strata categorical ## 3 numerical strata categorical ## 4 numerical strata categorical ## 5 categorical strata categorical ## 6 categorical strata categorical ## 7 categorical &lt;NA&gt; &lt;NA&gt; ## 8 categorical &lt;NA&gt; &lt;NA&gt; ## 9 numerical &lt;NA&gt; &lt;NA&gt; ## 10 numerical &lt;NA&gt; &lt;NA&gt; ## 11 categorical &lt;NA&gt; &lt;NA&gt; ## 12 categorical &lt;NA&gt; &lt;NA&gt; ## 13 categorical b9_hohh_marital_status categorical ## 14 categorical b9_hohh_marital_status categorical ## 15 numerical b9_hohh_marital_status categorical ## 16 numerical b9_hohh_marital_status categorical ## 17 categorical b9_hohh_marital_status categorical ## hypothesis.type repeat.for.variable ## 1 group_difference &lt;NA&gt; ## 2 group_difference &lt;NA&gt; ## 3 group_difference &lt;NA&gt; ## 4 group_difference &lt;NA&gt; ## 5 group_difference &lt;NA&gt; ## 6 group_difference &lt;NA&gt; ## 7 direct_reporting &lt;NA&gt; ## 8 direct_reporting &lt;NA&gt; ## 9 direct_reporting &lt;NA&gt; ## 10 direct_reporting &lt;NA&gt; ## 11 direct_reporting &lt;NA&gt; ## 12 direct_reporting &lt;NA&gt; ## 13 group_difference strata ## 14 group_difference strata ## 15 group_difference strata ## 16 group_difference strata ## 17 group_difference strata To use a DAP, you need to use the function from_analysisplan_map_to_output instead of the combination of map_to_case and map_to_result. It will look for the case itself. from_analysisplan_map_to_output a list of list of results. So you need to wriggle a bit around to come to a master dataframe. my_results &lt;- hypegrammaR::from_analysisplan_map_to_output(data =main_dataset, analysisplan = my_dap, weighting = my_weigthing_function, questionnaire = my_questionnaire, confidence_level = .90) long_table &lt;- my_results$results %&gt;% lapply(function(x) x[[&quot;summary.statistic&quot;]]) %&gt;% do.call(rbind, .) long_table %&gt;% head() ## dependent.var independent.var dependent.var.value ## 1 l4_which_difficult_access_health strata lack_of_facilities ## 2 l4_which_difficult_access_health strata lack_of_facilities ## 3 l4_which_difficult_access_health strata lack_of_facilities ## 4 l4_which_difficult_access_health strata lack_of_facilities ## 5 l4_which_difficult_access_health strata cost_of_medicine ## 6 l4_which_difficult_access_health strata cost_of_medicine ## independent.var.value numbers se min max repeat.var ## 1 20km_rural 0.2131148 NA 0.15352034 0.2727092 &lt;NA&gt; ## 2 20km_urban 0.1013514 NA 0.05248276 0.1502199 &lt;NA&gt; ## 3 5km_rural 0.2500000 NA 0.19147544 0.3085246 &lt;NA&gt; ## 4 5km_urban 0.1160221 NA 0.06915872 0.1628855 &lt;NA&gt; ## 5 20km_rural 0.8579235 NA 0.80711592 0.9087311 &lt;NA&gt; ## 6 20km_urban 0.8378378 NA 0.77815151 0.8975242 &lt;NA&gt; ## repeat.var.value ## 1 &lt;NA&gt; ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; 5.2 srvyr package The srvyr package aims to add dplyr like syntax to the survey package. It is a very useful package for a variety of aggregations of survey data. ###makes some additions. library(tidyverse) library(butteR) library(srvyr) library(kableExtra) df&lt;-read_csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;) dfsvy&lt;-as_survey(df) 5.2.1 Categorical variables srvyr package allows categorical variables to be broken down using a similar syntax as dplyr. Using dplyr you might typically calculate a percent mean as follows: df %&gt;% group_by(b9_hohh_marital_status) %&gt;% summarise( n=n() ) %&gt;% ungroup() %&gt;% mutate( pct_mean=n/sum(n) ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 6 x 3 ## b9_hohh_marital_status n pct_mean ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 divorced 183 0.113 ## 2 married 677 0.419 ## 3 separated_married_but_not_living_together 37 0.0229 ## 4 single 129 0.0798 ## 5 unmarried_but_living_together 96 0.0594 ## 6 widowed 495 0.306 To calculate the percent mean of a categorical variable using srvyr object is required. The syntax is quite similar to dplyr, but a bit less verbose. By specifying the vartype as ci we also get the upper and lower confidence intervals dfsvy %&gt;% group_by(b9_hohh_marital_status) %&gt;% summarise( pct_mean = survey_mean(vartype = &quot;ci&quot;) ) ## # A tibble: 6 x 4 ## b9_hohh_marital_status pct_mean pct_mean_low pct_mean_upp ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 divorced 0.113 0.0977 0.129 ## 2 married 0.419 0.395 0.443 ## 3 separated_married_but_not_living_together 0.0229 0.0156 0.0302 ## 4 single 0.0798 0.0666 0.0930 ## 5 unmarried_but_living_together 0.0594 0.0478 0.0709 ## 6 widowed 0.306 0.284 0.329 5.2.2 Numeric variables srvyr treats the calculation/aggregation of numeric variables differently in an attempt to mirror dplyr syntax to calculate the mean and median expenditure in dplyr you would likely do the following df %&gt;% summarise( mean_expenditure= mean(n1_HH_total_expenditure,na.rm=T), median_expenditure=median(n1_HH_total_expenditure,na.rm=T), ) ## # A tibble: 1 x 2 ## mean_expenditure median_expenditure ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5129. 4000 If you wanted to subset this by another variable in dplyr you would add the group_by argument df %&gt;% group_by(strata) %&gt;% summarise( mean_expenditure= mean(n1_HH_total_expenditure,na.rm=T), median_expenditure=median(n1_HH_total_expenditure,na.rm=T), ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 4 x 3 ## strata mean_expenditure median_expenditure ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20km_rural 5488. 4000 ## 2 20km_urban 6208. 5000 ## 3 5km_rural 3919. 3075 ## 4 5km_urban 4942. 4000 This is the reason why the syntax also varies between categorical and numeric variables in srvyr. Therefore, to do the same using srvyr you would do the following (with a survey object). Note that due to this difference in syntax the na.rm argument works for numeric variables, but does not work for categorical variables. This was modified when srvyr was updated from v 0.3.8 dfsvy %&gt;% summarise( mean= survey_mean(n1_HH_total_expenditure,na.rm=T,vartype = &quot;ci&quot;), ) ## mean mean_low mean_upp ## 1 5128.962 4891.389 5366.536 similar to dplyr you can easily add a group_by argument to add a subset calculation dfsvy %&gt;% group_by(strata) %&gt;% summarise( mean= survey_mean(n1_HH_total_expenditure,na.rm=T,vartype = &quot;ci&quot;), ) ## # A tibble: 4 x 4 ## strata mean mean_low mean_upp ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20km_rural 5488. 4980. 5996. ## 2 20km_urban 6208. 5661. 6756. ## 3 5km_rural 3919. 3469. 4370. ## 4 5km_urban 4942. 4604. 5280. 5.3 butteR survey_collapse The survey_collapse function available in butteR aggregates both categorical and numerical columns of a srvyr object. It provides a standardized format output that includes mean/pct mean (point estimates), and the upper/lower confidence intervals along with the unweighted number/frequency for each response option. The survey_collapse function is built around the great srvyr package. The srvyr package is a more modern/tidyverse style wrapper for the survey package. Both the srvyr and survye packages are great and there use is highligh encouraged. The main advantages of survey_collapse The standardized output produced Ability to analyze both categorical and numerical columns with a consistent syntax Batch analyses and ability to perform many different subsetting investigations with ease Below is an example of its use. First we must read in some data and make it into a srvyr object ###makes some additions. library(tidyverse) library(butteR) library(srvyr) library(kableExtra) df&lt;-read_csv(&quot;inputs/UKR2007_MSNA20_HH_dataset_main_rcop.csv&quot;) dfsvy&lt;-as_survey(df) For the purpose of the example I next choose a variety of different column types to analyze. As you can see I have selected select_one (categorical), select_multiple (binary categorical), and numerical columns. I then put these all into one vector. # here are some random concatenated select multiple parent questions select_multiple_parent_cols&lt;-c(&quot;l4_which_difficult_access_health&quot;, &quot;j10_education_security_concerns_in_the_vicinity_of_facility&quot;) numeric_cols&lt;- c(&quot;b7_hohh_age&quot;, &quot;b5_age&quot;) select_one_cols&lt;- c(&quot;b9_hohh_marital_status&quot;, &quot;d1_hh_displacement_status&quot;) mixed_columns&lt;- c(select_multiple_parent_cols, numeric_cols, select_one_cols) A nice feature of the standardized output produced by survey_collapse is that you can perform variety of different types of analyses and then bind them together into one dataframe/tibble. Therefore I fill an empty list with analysis to facilitate binding later. For the first analyses I simply aggregate all the columns specified as mean/pct mean. I next analyze the same variable but this time subset/disaggreated by the strata column. Its a good idea to mutate an extra column indicating what exact analysis was done so that when they are binded together later they can more easily be manipulated outputs&lt;-list() outputs$overall&lt;-butteR::survey_collapse(df = dfsvy,vars_to_analyze = mixed_columns) %&gt;% mutate(analysis_level= &quot;overall&quot;) outputs$strata&lt;-butteR::survey_collapse(df = dfsvy,vars_to_analyze = mixed_columns,disag = &quot;strata&quot;) %&gt;% mutate(analysis_level= &quot;strata&quot;) Here is an example of what the long format data looks like as a table. variable variable_val subset_1_name subset_1_val mean/pct mean/pct_low mean/pct_upp n_unweighted analysis_level b7_hohh_age strata 20km_rural 0.0000000 0.0000000 0.0000000 0 strata b7_hohh_age strata 20km_urban 0.0000000 0.0000000 0.0000000 0 strata b7_hohh_age strata 5km_rural 0.0000000 0.0000000 0.0000000 0 strata b7_hohh_age strata 5km_urban 0.0000000 0.0000000 0.0000000 0 strata b5_age strata 20km_rural 0.0000000 0.0000000 0.0000000 0 strata b5_age strata 20km_urban 0.0000000 0.0000000 0.0000000 0 strata b5_age strata 5km_rural 0.0000000 0.0000000 0.0000000 0 strata b5_age strata 5km_urban 0.0000000 0.0000000 0.0000000 0 strata b9_hohh_marital_status divorced strata 20km_rural 0.1007371 0.0714654 0.1300089 41 strata b9_hohh_marital_status married strata 20km_rural 0.4594595 0.4109922 0.5079267 187 strata b9_hohh_marital_status separated_married_but_not_living_together strata 20km_rural 0.0196560 0.0061556 0.0331565 8 strata b9_hohh_marital_status single strata 20km_rural 0.0515971 0.0300831 0.0731110 21 strata b9_hohh_marital_status unmarried_but_living_together strata 20km_rural 0.0884521 0.0608365 0.1160677 36 strata b9_hohh_marital_status widowed strata 20km_rural 0.2800983 0.2364263 0.3237702 114 strata b9_hohh_marital_status divorced strata 20km_urban 0.1138614 0.0828546 0.1448681 46 strata b9_hohh_marital_status married strata 20km_urban 0.4331683 0.3847987 0.4815379 175 strata b9_hohh_marital_status separated_married_but_not_living_together strata 20km_urban 0.0247525 0.0095860 0.0399189 10 strata b9_hohh_marital_status single strata 20km_urban 0.1039604 0.0741674 0.1337534 42 strata b9_hohh_marital_status unmarried_but_living_together strata 20km_urban 0.0495050 0.0283303 0.0706796 20 strata b9_hohh_marital_status widowed strata 20km_urban 0.2747525 0.2311781 0.3183268 111 strata b9_hohh_marital_status divorced strata 5km_rural 0.1019900 0.0723749 0.1316052 41 strata b9_hohh_marital_status married strata 5km_rural 0.3955224 0.3476737 0.4433711 159 strata b9_hohh_marital_status separated_married_but_not_living_together strata 5km_rural 0.0199005 0.0062339 0.0335671 8 strata b9_hohh_marital_status single strata 5km_rural 0.0820896 0.0552275 0.1089516 33 strata b9_hohh_marital_status unmarried_but_living_together strata 5km_rural 0.0522388 0.0304647 0.0740129 21 strata b9_hohh_marital_status widowed strata 5km_rural 0.3482587 0.3016375 0.3948799 140 strata b9_hohh_marital_status divorced strata 5km_urban 0.1361386 0.1026629 0.1696143 55 strata b9_hohh_marital_status married strata 5km_urban 0.3861386 0.3386134 0.4336638 156 strata b9_hohh_marital_status separated_married_but_not_living_together strata 5km_urban 0.0272277 0.0113412 0.0431142 11 strata b9_hohh_marital_status single strata 5km_urban 0.0816832 0.0549482 0.1084181 33 strata b9_hohh_marital_status unmarried_but_living_together strata 5km_urban 0.0470297 0.0263643 0.0676951 19 strata b9_hohh_marital_status widowed strata 5km_urban 0.3217822 0.2761803 0.3673841 130 strata d1_hh_displacement_status displaced_and_idp_status strata 20km_rural 0.0466830 0.0261663 0.0671998 19 strata d1_hh_displacement_status displaced_but_does_not_have_idp_status strata 20km_rural 0.0024570 -0.0023578 0.0072718 1 strata d1_hh_displacement_status no strata 20km_rural 0.9115479 0.8839323 0.9391635 371 strata d1_hh_displacement_status partially_displaced_and_dont_have_idp_status strata 20km_rural 0.0073710 -0.0009479 0.0156899 3 strata d1_hh_displacement_status partially_displaced_and_have_idp_status strata 20km_rural 0.0221130 0.0078116 0.0364144 9 strata d1_hh_displacement_status used_to_be_displaced_but_returned_and_has_no_status_of_idp strata 20km_rural 0.0098280 0.0002340 0.0194220 4 strata d1_hh_displacement_status displaced_and_idp_status strata 20km_urban 0.0272277 0.0113412 0.0431142 11 strata d1_hh_displacement_status no strata 20km_urban 0.9603960 0.9413585 0.9794336 388 strata d1_hh_displacement_status partially_displaced_and_have_idp_status strata 20km_urban 0.0099010 0.0002361 0.0195659 4 strata d1_hh_displacement_status used_to_be_displaced_but_returned_and_has_no_status_of_idp strata 20km_urban 0.0024752 -0.0023753 0.0073258 1 strata d1_hh_displacement_status displaced_and_idp_status strata 5km_rural 0.0895522 0.0616100 0.1174944 36 strata d1_hh_displacement_status displaced_but_does_not_have_idp_status strata 5km_rural 0.0049751 -0.0019100 0.0118603 2 strata d1_hh_displacement_status no strata 5km_rural 0.8781095 0.8460944 0.9101245 353 strata d1_hh_displacement_status partially_displaced_and_have_idp_status strata 5km_rural 0.0024876 -0.0023871 0.0073622 1 strata d1_hh_displacement_status used_to_be_displaced_but_returned_and_has_a_status_of_idp strata 5km_rural 0.0024876 -0.0023871 0.0073622 1 strata d1_hh_displacement_status used_to_be_displaced_but_returned_and_has_no_status_of_idp strata 5km_rural 0.0223881 0.0079108 0.0368653 9 strata d1_hh_displacement_status displaced_and_idp_status strata 5km_urban 0.0618812 0.0383618 0.0854005 25 strata d1_hh_displacement_status displaced_but_does_not_have_idp_status strata 5km_urban 0.0049505 -0.0019007 0.0118017 2 strata d1_hh_displacement_status no strata 5km_urban 0.9108911 0.8830805 0.9387017 368 strata d1_hh_displacement_status partially_displaced_and_dont_have_idp_status strata 5km_urban 0.0024752 -0.0023753 0.0073258 1 strata d1_hh_displacement_status partially_displaced_and_have_idp_status strata 5km_urban 0.0049505 -0.0019007 0.0118017 2 strata d1_hh_displacement_status used_to_be_displaced_but_returned_and_has_a_status_of_idp strata 5km_urban 0.0024752 -0.0023753 0.0073258 1 strata d1_hh_displacement_status used_to_be_displaced_but_returned_and_has_no_status_of_idp strata 5km_urban 0.0123762 0.0015841 0.0231684 5 strata This is a great format for manipulating/filtering and then graphing with ggplot output_df&lt;- bind_rows(outputs) output_df %&gt;% filter(analysis_level==&quot;overall&quot;) %&gt;% mutate(question_val= paste0(variable,&quot;.&quot;,variable_val)) %&gt;% ggplot(aes(x= question_val,y= `mean/pct`))+ geom_point(stat=&quot;identity&quot;, position = position_dodge(width = 0.3))+ geom_errorbar(aes(ymin= `mean/pct_low`, ymax= `mean/pct_upp`), width=0.2,position = position_dodge(width = 0.3))+ scale_y_continuous(labels = scales::percent,breaks = seq(0,1,by=0.1))+ coord_flip()+ theme_bw()+ theme( axis.title = element_blank(), axis.text.x = element_text(angle=90), legend.title= element_blank() ) # Easy to plot subset findings as well! output_df %&gt;% filter(analysis_level==&quot;strata&quot;) %&gt;% mutate(question_val= paste0(variable,&quot;.&quot;,variable_val)) %&gt;% ggplot(aes(x= question_val,y= `mean/pct`, color=subset_1_val))+ geom_point(stat=&quot;identity&quot;, position = position_dodge(width = 0.3))+ geom_errorbar(aes(ymin= `mean/pct_low`, ymax= `mean/pct_upp`), width=0.2,position = position_dodge(width = 0.3))+ scale_y_continuous(labels = scales::percent,breaks = seq(0,1,by=0.1))+ coord_flip()+ theme_bw()+ theme( axis.title = element_blank(), axis.text.x = element_text(angle=90), legend.title= element_blank() ) 5.3.1 select_one 5.3.2 select_mutiple 5.4 Analysis with numerical variables Summarytools (CRAN package) Spatstat hypegrammaR / koboquest / butteR ### Averages ### Median 5.5 Weights surveyweights survey (CRAN package) srvyr (CRAN package) 5.6 Repeating the above 5.7 Top 3 5.8 Borda count 5.9 Hypothesis testing 5.9.1 T-test 5.9.2 ANOVA 5.9.3 chi-squares "],["outputs.html", "6 Outputs 6.1 From long to large table 6.2 Merge file 6.3 Graphs 6.4 Labels 6.5 Dashboarding - Sharing information 6.6 Outputs with hypothesis testing results", " 6 Outputs 6.1 From long to large table How to move from a tidy format to a large format 6.2 Merge file How to create a merge file 6.3 Graphs 6.3.1 spider graphs 6.3.2 prison graphs 6.3.3 venn diagram 6.4 Labels 6.4.1 change from xml to label 6.4.2 change from label to xml 6.5 Dashboarding - Sharing information Html files Tableau Power BI Shiny 6.6 Outputs with hypothesis testing results "],["miscellaneous.html", "7 Miscellaneous", " 7 Miscellaneous Geocoding - stringdist R output to be used with SPSS Individual loops analysis Calculation of CI guidelines on hypothesis testing "]]
